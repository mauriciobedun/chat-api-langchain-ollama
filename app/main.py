from fastapi import FastAPI, Request
from fastapi.middleware.cors import CORSMiddleware
from fastapi.responses import JSONResponse
import time
import logging
from contextlib import asynccontextmanager

from app.api.chat import router as chat_router
from app.services.qa import qa_service

# Configurar logging
logging.basicConfig(
    level=logging.INFO,
    format="%(asctime)s - %(name)s - %(levelname)s - %(message)s"
)
logger = logging.getLogger(__name__)


@asynccontextmanager
async def lifespan(app: FastAPI):
    """Gerenciador de ciclo de vida da aplica√ß√£o"""
    # Startup
    logger.info("üöÄ Iniciando API de Chat com FastAPI + LangChain + Ollama")
    
    # Verificar conex√£o com Ollama
    try:
        if qa_service.check_ollama_connection():
            logger.info("‚úÖ Conex√£o com Ollama estabelecida")
        else:
            logger.warning("‚ö†Ô∏è  Ollama n√£o est√° conectado - algumas funcionalidades podem n√£o funcionar")
    except Exception as e:
        logger.error(f"‚ùå Erro ao conectar com Ollama: {e}")
    
    yield
    
    # Shutdown
    logger.info("üõë Encerrando API de Chat")


# Criar aplica√ß√£o FastAPI
app = FastAPI(
    title="API de Chat com LangChain e Ollama",
    description="""
    ü§ñ **API de Chat Inteligente**
    
    Esta API fornece funcionalidades de chat usando LangChain e Ollama, incluindo:
    
    - **Chat b√°sico**: Conversas com modelo de linguagem
    - **Mem√≥ria de sess√£o**: Manuten√ß√£o de hist√≥rico por sess√£o
    - **RAG (Retrieval Augmented Generation)**: Perguntas sobre documentos
    - **Upload de documentos**: Suporte para .txt e .md
    - **Observabilidade**: Health checks e m√©tricas
    
    ## üöÄ Como usar
    
    1. **Chat b√°sico**: Use o endpoint `/chat` para conversas simples
    2. **Upload de documentos**: Use `/upload-document` para carregar arquivos
    3. **Perguntas sobre documentos**: Use `/ask` para RAG
    4. **Health check**: Use `/health` para verificar status
    
    ## üìä Monitoramento
    
    - `/health`: Status da API e Ollama
    - `/stats`: Estat√≠sticas detalhadas do servi√ßo
    """,
    version="1.0.0",
    contact={
        "name": "Desenvolvedor",
        "email": "dev@example.com",
    },
    license_info={
        "name": "MIT",
        "url": "https://opensource.org/licenses/MIT",
    },
    lifespan=lifespan
)

# Configurar CORS
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],  # Em produ√ß√£o, especifique dom√≠nios espec√≠ficos
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)


# Middleware para logging de requisi√ß√µes
@app.middleware("http")
async def log_requests(request: Request, call_next):
    """Middleware para log estruturado de requisi√ß√µes"""
    start_time = time.time()
    
    # Log da requisi√ß√£o
    logger.info(
        f"üì• {request.method} {request.url.path} - "
        f"Client: {request.client.host if request.client else 'unknown'}"
    )
    
    # Processar requisi√ß√£o
    response = await call_next(request)
    
    # Calcular tempo de processamento
    process_time = time.time() - start_time
    process_time_ms = int(process_time * 1000)
    
    # Log da resposta
    logger.info(
        f"üì§ {request.method} {request.url.path} - "
        f"Status: {response.status_code} - "
        f"Time: {process_time_ms}ms"
    )
    
    # Adicionar header com tempo de processamento
    response.headers["X-Process-Time"] = str(process_time_ms)
    
    return response


# Incluir routers
app.include_router(chat_router, prefix="/api/v1")


# Endpoint raiz
@app.get("/", tags=["Root"])
async def root():
    """Endpoint raiz com informa√ß√µes da API"""
    return {
        "message": "ü§ñ API de Chat com FastAPI + LangChain + Ollama",
        "version": "1.0.0",
        "status": "online",
        "docs": "/docs",
        "health": "/api/v1/health",
        "endpoints": {
            "chat": "/api/v1/chat",
            "upload": "/api/v1/upload-document", 
            "ask": "/api/v1/ask",
            "health": "/api/v1/health",
            "stats": "/api/v1/stats"
        }
    }


# Handler global de exce√ß√µes
@app.exception_handler(Exception)
async def global_exception_handler(request: Request, exc: Exception):
    """Handler global para exce√ß√µes n√£o tratadas"""
    logger.error(f"‚ùå Erro n√£o tratado em {request.url.path}: {exc}")
    
    return JSONResponse(
        status_code=500,
        content={
            "error": "Erro interno do servidor",
            "message": "Ocorreu um erro inesperado. Tente novamente mais tarde.",
            "path": str(request.url.path)
        }
    )


if __name__ == "__main__":
    import uvicorn
    
    logger.info("üîß Iniciando servidor de desenvolvimento")
    uvicorn.run(
        "app.main:app",
        host="0.0.0.0",
        port=8000,
        reload=True,
        log_level="info"
    ) 